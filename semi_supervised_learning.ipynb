{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from utils import *\n",
    "from model_def import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://github.com/pytorch/examples/blob/master/imagenet/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args = defaultdict(lambda:False, {'print_freq': 250, 'lr':.03,'arch':'resnet18'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_sup_train, data_loader_sup_val, data_loader_unsup = image_loader('data/ssl_data_96',32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sup_loader, unsup_loader, model, criterion, optimizer, epoch, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(len(sup_loader), batch_time, data_time, losses, top1,\n",
    "                             top5, prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, ((input_sup, target_sup), (input_unsup,target_unsup)) in enumerate(zip(sup_loader,unsup_loader)):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input_sup = input_sup.to(device)\n",
    "        target_sup = target_sup.to(device)\n",
    "        input_unsup = input_sup.to(device)\n",
    "        target_unsup = target_sup.to(device)\n",
    "        \n",
    "\n",
    "        # compute output\n",
    "        output_sup = model(input_sup)\n",
    "        #output_unsup = model(input_unsup)\n",
    "        loss = criterion(output_sup, target_sup)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output_sup, target_sup, topk=(1, 5))\n",
    "        losses.update(loss.item(), input_sup.size(0))\n",
    "        top1.update(acc1[0], input_sup.size(0))\n",
    "        top5.update(acc5[0], input_sup.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args['print_freq'] == 0:\n",
    "            progress.print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(len(val_loader), batch_time, losses, top1, top5,\n",
    "                             prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input_val, target_val) in enumerate(val_loader):\n",
    "            input_val = input_val.to(device)\n",
    "            target_val = target_val.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output_val = model(input_val)\n",
    "            loss = criterion(output_val, target_val)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output_val, target_val, topk=(1, 5))\n",
    "            losses.update(loss.item(), input_val.size(0))\n",
    "            top1.update(acc1[0], input_val.size(0))\n",
    "            top5.update(acc5[0], input_val.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % args['print_freq'] == 0:\n",
    "                progress.print(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/2000]\tTime  1.715 ( 1.715)\tData  0.109 ( 0.109)\tLoss 8.6142e+00 (8.6142e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Epoch: [0][ 250/2000]\tTime  0.103 ( 0.114)\tData  0.002 ( 0.003)\tLoss 7.0099e+00 (8.6432e+00)\tAcc@1   0.00 (  0.02)\tAcc@5   0.00 (  0.35)\n",
      "Epoch: [0][ 500/2000]\tTime  0.111 ( 0.111)\tData  0.003 ( 0.003)\tLoss 6.9405e+00 (7.8106e+00)\tAcc@1   0.00 (  0.06)\tAcc@5   0.00 (  0.40)\n",
      "Epoch: [0][ 750/2000]\tTime  0.112 ( 0.111)\tData  0.003 ( 0.002)\tLoss 6.9734e+00 (7.5282e+00)\tAcc@1   0.00 (  0.08)\tAcc@5   0.00 (  0.40)\n",
      "Epoch: [0][1000/2000]\tTime  0.100 ( 0.110)\tData  0.003 ( 0.002)\tLoss 6.9293e+00 (7.3853e+00)\tAcc@1   0.00 (  0.07)\tAcc@5   0.00 (  0.39)\n",
      "Epoch: [0][1250/2000]\tTime  0.114 ( 0.110)\tData  0.003 ( 0.002)\tLoss 6.9059e+00 (7.3005e+00)\tAcc@1   0.00 (  0.07)\tAcc@5   0.00 (  0.39)\n",
      "Epoch: [0][1500/2000]\tTime  0.110 ( 0.110)\tData  0.003 ( 0.003)\tLoss 7.0110e+00 (7.2440e+00)\tAcc@1   0.00 (  0.08)\tAcc@5   0.00 (  0.41)\n",
      "Epoch: [0][1750/2000]\tTime  0.116 ( 0.110)\tData  0.003 ( 0.003)\tLoss 7.0397e+00 (7.2032e+00)\tAcc@1   0.00 (  0.09)\tAcc@5   0.00 (  0.42)\n",
      "Test: [   0/2000]\tTime  0.103 ( 0.103)\tLoss 6.8761e+00 (6.8761e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Test: [ 250/2000]\tTime  0.029 ( 0.031)\tLoss 7.1169e+00 (7.1453e+00)\tAcc@1   0.00 (  0.09)\tAcc@5   0.00 (  0.59)\n",
      "Test: [ 500/2000]\tTime  0.031 ( 0.030)\tLoss 6.9912e+00 (7.1414e+00)\tAcc@1   0.00 (  0.12)\tAcc@5   0.00 (  0.54)\n",
      "Test: [ 750/2000]\tTime  0.030 ( 0.030)\tLoss 6.9671e+00 (7.1575e+00)\tAcc@1   0.00 (  0.09)\tAcc@5   3.12 (  0.49)\n",
      "Test: [1000/2000]\tTime  0.070 ( 0.032)\tLoss 7.0018e+00 (7.1797e+00)\tAcc@1   0.00 (  0.11)\tAcc@5   0.00 (  0.51)\n",
      "Test: [1250/2000]\tTime  0.031 ( 0.033)\tLoss 7.0605e+00 (7.1727e+00)\tAcc@1   0.00 (  0.10)\tAcc@5   3.12 (  0.53)\n",
      "Test: [1500/2000]\tTime  0.031 ( 0.032)\tLoss 6.9869e+00 (7.1740e+00)\tAcc@1   0.00 (  0.11)\tAcc@5   0.00 (  0.53)\n",
      "Test: [1750/2000]\tTime  0.030 ( 0.032)\tLoss 6.9524e+00 (7.1766e+00)\tAcc@1   0.00 (  0.11)\tAcc@5   0.00 (  0.52)\n",
      " * Acc@1 0.098 Acc@5 0.500\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'collections.defaultdict' object has no attribute 'arch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7d6cc6de4a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     save_checkpoint({\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;34m'arch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;34m'best_acc1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_acc1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.defaultdict' object has no attribute 'arch'"
     ]
    }
   ],
   "source": [
    "global best_acc1\n",
    "# create model\n",
    "model = resnet34() if args['arch']=='resnet32' else resnet18()\n",
    "model = model.to(device)\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "# torch.optim.SGD(model.parameters(), args['lr'],\n",
    "#                             momentum=args.momentum,\n",
    "#                             weight_decay=args.weight_decay)\n",
    "\n",
    "# optionally resume from a checkpoint\n",
    "if args['resume']:\n",
    "    if os.path.isfile(args['resume']):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args['resume']))\n",
    "        checkpoint = torch.load(args['resume'])\n",
    "        args['start_epoch'] = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_acc1']\n",
    "        \n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args['resume']))\n",
    "else:\n",
    "    best_acc1 = -1\n",
    "\n",
    "for epoch in range(0, 3):\n",
    "    #adjust_learning_rate(optimizer, epoch, args)\n",
    "    # train for one epoch\n",
    "    train(data_loader_sup_train, data_loader_unsup, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(data_loader_sup_val, model, criterion, args)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': args.arch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
